import streamlit as st
import logging
import pickle
import base64
import requests
import json
import os
from github import Github
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def validate_api_key(api_key):
    """OpenAI API í‚¤ í˜•ì‹ ê²€ì¦"""
    return api_key and len(api_key) > 20

def process_json(file):
    """JSON íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        content = file.getvalue().decode('utf-8')
        data = json.loads(content)
        
        # JSON ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        text_content = json.dumps(data, ensure_ascii=False, indent=2)
        
        # Document ê°ì²´ ìƒì„±
        return [Document(
            page_content=text_content,
            metadata={"source": file.name}
        )]
    except Exception as e:
        logger.error(f"JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def get_text_chunks(documents):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=900,
        chunk_overlap=100
    )
    return text_splitter.split_documents(documents)

def create_vector_store(documents):
    """ë²¡í„° ì €ì¥ì†Œ ìƒì„±"""
    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    return FAISS.from_documents(documents=documents, embedding=embeddings)

def save_vector_store(vectorstore, directory="vector_store"):
    """ë²¡í„° ì €ì¥ì†Œë¥¼ ë¡œì»¬ì— ì €ì¥"""
    try:
        # ì €ì¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
        if not os.path.exists(directory):
            os.makedirs(directory)
        
        file_path = os.path.join(directory, "index.pkl")
        
        # ë²¡í„° ì €ì¥ì†Œë¥¼ íŒŒì¼ë¡œ ì €ì¥
        with open(file_path, 'wb') as f:
            pickle.dump(vectorstore, f)
        
        return True, file_path
    except Exception as e:
        logger.error(f"ì €ì¥ ì˜¤ë¥˜: {e}")
        return False, str(e)

def get_conversation_chain(vectorstore, openai_api_key):
    """ëŒ€í™” ì²´ì¸ ìƒì„±"""
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-4', temperature=0)
    
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_type='mmr', verbose=True),
        memory=ConversationBufferMemory(
            memory_key='chat_history',
            return_messages=True,
            output_key='answer'
        ),
        get_chat_history=lambda h: h,
        return_source_documents=True,
        verbose=True
    )

    return conversation_chain

def main():
    try:
        # í˜ì´ì§€ ì„¤ì •
        st.set_page_config(
            page_title="ìš”ë¦¬ ë„ìš°ë¯¸",
            page_icon="ğŸ³",
            layout="wide"
        )

        st.title("ìš”ë¦¬ ë„ìš°ë¯¸ ğŸ³")

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "conversation" not in st.session_state:
            st.session_state.conversation = None
        if 'messages' not in st.session_state:
            st.session_state['messages'] = [
                {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ìš”ë¦¬ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì–´ë–¤ ìš”ë¦¬ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"}
            ]
        if 'vectorstore' not in st.session_state:
            st.session_state.vectorstore = None

        # ì‚¬ì´ë“œë°” ì„¤ì •
        with st.sidebar:
            st.header("ì„¤ì •")
            
            # API í‚¤ ì…ë ¥
            openai_api_key = st.text_input("OpenAI API Key", type="password")
            if not openai_api_key:
                st.info("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ”‘")

            # JSON íŒŒì¼ ì—…ë¡œë“œ
            st.header("JSON íŒŒì¼ ì—…ë¡œë“œ")
            uploaded_file = st.file_uploader("JSON íŒŒì¼ ì„ íƒ", type=["json"])
            
            # ì²˜ë¦¬ ë²„íŠ¼ë“¤
            col1, col2 = st.columns(2)
            with col1:
                process_button = st.button("íŒŒì¼ ì²˜ë¦¬")
            with col2:
                save_button = st.button("ë²¡í„° ì €ì¥")

        # JSON íŒŒì¼ ì²˜ë¦¬
        if uploaded_file and process_button:
            if not validate_api_key(openai_api_key):
                st.error("ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()

            try:
                with st.spinner("JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
                    # JSON ì²˜ë¦¬
                    documents = process_json(uploaded_file)
                    if not documents:
                        st.error("JSON íŒŒì¼ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        st.stop()
                    
                    # ì²­í¬ ìƒì„±
                    chunks = get_text_chunks(documents)
                    
                    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                    vectorstore = create_vector_store(chunks)
                    
                    # ì„¸ì…˜ì— ì €ì¥
                    st.session_state.vectorstore = vectorstore
                    st.session_state.conversation = get_conversation_chain(vectorstore, openai_api_key)
                    st.success("JSON íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")

            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        # ë²¡í„° ì €ì¥ì†Œ ì €ì¥
        if save_button:
            if not st.session_state.vectorstore:
                st.error("ì €ì¥í•  ë²¡í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € JSON íŒŒì¼ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
                st.stop()

            try:
                with st.spinner("ë²¡í„° ì €ì¥ì†Œ ì €ì¥ ì¤‘..."):
                    success, result = save_vector_store(st.session_state.vectorstore)
                    if success:
                        st.success(f"ë²¡í„° ì €ì¥ì†Œë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤! (ê²½ë¡œ: {result})")
                    else:
                        st.error(f"ì €ì¥ ì‹¤íŒ¨: {result}")

            except Exception as e:
                st.error(f"ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                logger.error(f"ì €ì¥ ì˜¤ë¥˜: {e}")

        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
        chat_container = st.container()
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.write(message["content"])

        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
            st.session_state.messages.append({"role": "user", "content": query})
            
            with st.chat_message("user"):
                st.write(query)

            if not st.session_state.conversation:
                st.warning("ë¨¼ì € JSON íŒŒì¼ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ë¨¼ì € JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”."
                })
                st.rerun()

            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    try:
                        result = st.session_state.conversation({"question": query})
                        response = result['answer']
                        source_documents = result.get('source_documents', [])

                        st.write(response)

                        if source_documents:
                            with st.expander("ì°¸ê³  ë¬¸ì„œ"):
                                for i, doc in enumerate(source_documents[:3], 1):
                                    st.markdown(f"**ì°¸ê³  {i}:** {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜')}")
                                    st.markdown(f"```\n{doc.page_content[:200]}...\n```")

                        st.session_state.messages.append({"role": "assistant", "content": response})

                    except Exception as e:
                        error_message = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        st.error(error_message)
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": error_message
                        })
                        logger.error(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")

    except Exception as e:
        logger.error(f"ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error("ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ì„ ì‹œë„í•´ì£¼ì„¸ìš”.")

if __name__ == '__main__':
    main()
