import streamlit as st
import logging
import pickle
import base64
import requests
import json
import os
from github import Github
from datetime import datetime

from langchain_openai import ChatOpenAI
from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.docstore.document import Document

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# GitHub ì €ì¥ì†Œ ì •ë³´
GITHUB_REPO = "Dawol2205/chatbot_test"
GITHUB_BRANCH = "main"
VECTOR_PATH = "vector_store"

def validate_api_key(api_key):
    """OpenAI API í‚¤ í˜•ì‹ ê²€ì¦"""
    return api_key and len(api_key) > 20

def validate_github_token(github_token):
    """GitHub í† í° ê²€ì¦"""
    if not github_token:
        return False
    try:
        g = Github(github_token)
        g.get_user().login
        return True
    except:
        return False

def process_json_file(file):
    """JSON íŒŒì¼ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    try:
        content = file.getvalue().decode('utf-8')
        data = json.loads(content)
        
        # JSON ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        text_content = json.dumps(data, ensure_ascii=False, indent=2)
        
        # Document ê°ì²´ ìƒì„±
        return Document(
            page_content=text_content,
            metadata={"source": file.name}
        )
    except Exception as e:
        logger.error(f"JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def process_json_files(files):
    """ì—¬ëŸ¬ JSON íŒŒì¼ ì²˜ë¦¬"""
    documents = []
    for file in files:
        doc = process_json_file(file)
        if doc:
            documents.append(doc)
    return documents

def save_vectorstore_to_github(vectorstore, github_token, repo_name=GITHUB_REPO, branch=GITHUB_BRANCH):
    """ë²¡í„° ì €ì¥ì†Œë¥¼ GitHubì— ì €ì¥"""
    try:
        # ë²¡í„° ì €ì¥ì†Œë¥¼ ë°”ì´íŠ¸ë¡œ ì§ë ¬í™”
        serialized_vectorstore = pickle.dumps(vectorstore)
        
        # base64ë¡œ ì¸ì½”ë”©
        encoded_content = base64.b64encode(serialized_vectorstore).decode()
        
        # GitHub API ì—°ê²°
        g = Github(github_token)
        repo = g.get_repo(repo_name)
        
        # íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        file_path = f"{VECTOR_PATH}/vectorstore_{timestamp}.pkl"
        
        try:
            # í´ë”ê°€ ì—†ëŠ” ê²½ìš° ìƒì„±
            try:
                repo.get_contents(VECTOR_PATH)
            except:
                repo.create_file(
                    f"{VECTOR_PATH}/.gitkeep",
                    "Initialize vector store directory",
                    "",
                    branch=branch
                )

            # ë²¡í„° ì €ì¥ì†Œ íŒŒì¼ ì €ì¥
            repo.create_file(
                file_path,
                f"Create vector store {timestamp}",
                encoded_content,
                branch=branch
            )
            
            return True, file_path
            
        except Exception as e:
            logger.error(f"GitHub íŒŒì¼ ìƒì„± ì˜¤ë¥˜: {e}")
            return False, str(e)
        
    except Exception as e:
        logger.error(f"GitHub ì €ì¥ ì˜¤ë¥˜: {e}")
        return False, str(e)

def get_text_chunks(documents):
    """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=900,
        chunk_overlap=100
    )
    return text_splitter.split_documents(documents)

def create_vector_store(documents):
    """ë²¡í„° ì €ì¥ì†Œ ìƒì„±"""
    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    
    return FAISS.from_documents(documents=documents, embedding=embeddings)

def get_conversation_chain(vectorstore, openai_api_key):
    """ëŒ€í™” ì²´ì¸ ìƒì„±"""
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-4', temperature=0)
    
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_type='mmr', verbose=True),
        memory=ConversationBufferMemory(
            memory_key='chat_history',
            return_messages=True,
            output_key='answer'
        ),
        get_chat_history=lambda h: h,
        return_source_documents=True,
        verbose=True
    )

    return conversation_chain

def main():
    try:
        # í˜ì´ì§€ ì„¤ì •
        st.set_page_config(
            page_title="ìš”ë¦¬ ë„ìš°ë¯¸",
            page_icon="ğŸ³",
            layout="wide",
            initial_sidebar_state="expanded"
        )

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        initialize_session_state()

        st.title("ìš”ë¦¬ ë„ìš°ë¯¸ ğŸ³")

        def initialize_session_state():
            """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
            if "initialized" not in st.session_state:
                st.session_state.initialized = True
            if "conversation" not in st.session_state:
                st.session_state.conversation = None
            if "messages" not in st.session_state:
                st.session_state.messages = [
                    {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ìš”ë¦¬ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì–´ë–¤ ìš”ë¦¬ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"}
                ]
            if "vectorstore" not in st.session_state:
                st.session_state.vectorstore = None

        # ì‚¬ì´ë“œë°” ì„¤ì •
        with st.sidebar:
            st.header("ì„¤ì •")
            
            # API í‚¤ ì…ë ¥
            openai_api_key = st.text_input("OpenAI API Key", type="password")
            if not openai_api_key:
                st.info("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ”‘")
            
            # GitHub í† í°
            github_token = st.text_input("GitHub Token", type="password")
            if not github_token:
                st.info("GitHub í† í°ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ”‘")

            # JSON íŒŒì¼ ì—…ë¡œë“œ
            st.header("JSON íŒŒì¼ ì—…ë¡œë“œ")
            uploaded_files = st.file_uploader(
                "JSON íŒŒì¼ ì„ íƒ",
                type=["json"],
                accept_multiple_files=True
            )
            
            # ì²˜ë¦¬ ë²„íŠ¼ë“¤
            col1, col2 = st.columns(2)
            with col1:
                process_button = st.button("íŒŒì¼ ì²˜ë¦¬")
            with col2:
                save_button = st.button("GitHubì— ì €ì¥")

        # JSON íŒŒì¼ ì²˜ë¦¬
        if uploaded_files and process_button:
            if not validate_api_key(openai_api_key):
                st.error("ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()

            try:
                with st.spinner("JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘..."):
                    # JSON ì²˜ë¦¬
                    documents = process_json_files(uploaded_files)
                    if not documents:
                        st.error("JSON íŒŒì¼ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        st.stop()
                    
                    # ì²­í¬ ìƒì„±
                    chunks = get_text_chunks(documents)
                    
                    # ë²¡í„° ì €ì¥ì†Œ ìƒì„±
                    vectorstore = create_vector_store(chunks)
                    
                    # ì„¸ì…˜ì— ì €ì¥
                    st.session_state.vectorstore = vectorstore
                    st.session_state.conversation = get_conversation_chain(vectorstore, openai_api_key)
                    st.success("JSON íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")

            except Exception as e:
                st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                logger.error(f"ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

        # GitHubì— ë²¡í„° ì €ì¥ì†Œ ì €ì¥
        if save_button:
            if not st.session_state.vectorstore:
                st.error("ì €ì¥í•  ë²¡í„° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € JSON íŒŒì¼ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
                st.stop()
                
            if not validate_github_token(github_token):
                st.error("ìœ íš¨í•œ GitHub í† í°ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                st.stop()

            try:
                with st.spinner("ë²¡í„° ì €ì¥ì†Œë¥¼ GitHubì— ì €ì¥í•˜ëŠ” ì¤‘..."):
                    success, result = save_vectorstore_to_github(
                        st.session_state.vectorstore,
                        github_token
                    )
                    if success:
                        st.success(f"ë²¡í„° ì €ì¥ì†Œë¥¼ GitHubì— ì €ì¥í–ˆìŠµë‹ˆë‹¤! (ê²½ë¡œ: {result})")
                    else:
                        st.error(f"GitHub ì €ì¥ ì‹¤íŒ¨: {result}")

            except Exception as e:
                st.error(f"GitHub ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                logger.error(f"GitHub ì €ì¥ ì˜¤ë¥˜: {e}")

        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
        chat_container = st.container()
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.write(message["content"])

        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
            st.session_state.messages.append({"role": "user", "content": query})
            
            with st.chat_message("user"):
                st.write(query)

            if not st.session_state.conversation:
                st.warning("ë¨¼ì € JSON íŒŒì¼ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ë¨¼ì € JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì²˜ë¦¬í•´ì£¼ì„¸ìš”."
                })
                return

            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    try:
                        result = st.session_state.conversation({"question": query})
                        response = result['answer']
                        source_documents = result.get('source_documents', [])

                        st.write(response)

                        if source_documents:
                            with st.expander("ì°¸ê³  ë¬¸ì„œ"):
                                for i, doc in enumerate(source_documents[:3], 1):
                                    st.markdown(f"**ì°¸ê³  {i}:** {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜')}")
                                    st.markdown(f"```\n{doc.page_content[:200]}...\n```")

                        st.session_state.messages.append({"role": "assistant", "content": response})

                    except Exception as e:
                        error_message = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        st.error(error_message)
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": error_message
                        })
                        logger.error(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")

    except Exception as e:
        logger.error(f"ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error("ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ì„ ì‹œë„í•´ì£¼ì„¸ìš”.")

if __name__ == '__main__':
    main()
