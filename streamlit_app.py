import streamlit as st
import logging
import pickle
import base64
import requests
from github import Github
from datetime import datetime

from langchain_community.chat_models import ChatOpenAI
from langchain_community.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_community.vectorstores import FAISS

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# GitHub ì €ì¥ì†Œ ì •ë³´
GITHUB_REPO = "Dawol2205/chatbot_test"
GITHUB_BRANCH = "main"
VECTOR_PATH = "vector_store"  # ë²¡í„° ì €ì¥ì†Œê°€ ìˆëŠ” ë””ë ‰í† ë¦¬

def validate_api_key(api_key):
    """OpenAI API í‚¤ í˜•ì‹ ê²€ì¦"""
    return api_key and len(api_key) > 20

def get_github_file_content(token, repo_name, file_path, branch="main"):
    """GitHubì—ì„œ íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
    try:
        g = Github(token)
        repo = g.get_repo(repo_name)
        content = repo.get_contents(file_path, ref=branch)
        
        decoded_content = base64.b64decode(content.content)
        return True, decoded_content
    except Exception as e:
        logger.error(f"GitHub íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return False, str(e)

def load_vector_store(github_token, filepath):
    """GitHubì—ì„œ ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ"""
    try:
        success, content = get_github_file_content(github_token, GITHUB_REPO, filepath, GITHUB_BRANCH)
        if success:
            vectorstore = pickle.loads(content)
            return True, vectorstore
        else:
            return False, content
    except Exception as e:
        logger.error(f"ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return False, str(e)

def get_conversation_chain(vectorstore, openai_api_key):
    """ëŒ€í™” ì²´ì¸ ìƒì„±"""
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-4', temperature=0)
    
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        chain_type="stuff",
        retriever=vectorstore.as_retriever(search_type='mmr', verbose=True),
        memory=ConversationBufferMemory(
            memory_key='chat_history',
            return_messages=True,
            output_key='answer'
        ),
        get_chat_history=lambda h: h,
        return_source_documents=True,
        verbose=True
    )

    return conversation_chain

def main():
    try:
        # í˜ì´ì§€ ì„¤ì •
        st.set_page_config(
            page_title="ìš”ë¦¬ ë„ìš°ë¯¸",
            page_icon="ğŸ³",
            layout="wide"
        )

        if 'initialized' not in st.session_state:
            st.session_state.initialized = True
            st.experimental_rerun()

        st.title("ìš”ë¦¬ ë„ìš°ë¯¸ ğŸ³")

        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if "conversation" not in st.session_state:
            st.session_state.conversation = None
        if 'messages' not in st.session_state:
            st.session_state['messages'] = [
                {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ìš”ë¦¬ ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì–´ë–¤ ìš”ë¦¬ì— ëŒ€í•´ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"}
            ]
        if 'vectorstore' not in st.session_state:
            st.session_state.vectorstore = None

        # ì‚¬ì´ë“œë°” ì„¤ì •
        with st.sidebar:
            st.header("ì„¤ì •")
            
            # API í‚¤ ì…ë ¥
            openai_api_key = st.text_input("OpenAI API Key", type="password")
            if not openai_api_key:
                st.info("OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ”‘")

            # GitHub í† í° ì…ë ¥
            github_token = st.text_input("GitHub Token", type="password")
            if not github_token:
                st.info("GitHub í† í°ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="ğŸ”‘")

            # ë²¡í„° DB ë¡œë“œ ë²„íŠ¼
            if st.button("ë²¡í„° DB ë¡œë“œ"):
                if not validate_api_key(openai_api_key):
                    st.error("ìœ íš¨í•œ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    st.stop()

                try:
                    with st.spinner("ë²¡í„° DBë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
                        # ë²¡í„° ì €ì¥ì†Œ ë¶ˆëŸ¬ì˜¤ê¸°
                        success, result = load_vector_store(github_token, f"{VECTOR_PATH}/index.pkl")
                        
                        if success:
                            st.session_state.vectorstore = result
                            st.session_state.conversation = get_conversation_chain(result, openai_api_key)
                            st.success("ë²¡í„° DBë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤!")
                        else:
                            st.error(f"ë²¡í„° DB ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {result}")
                            
                except Exception as e:
                    st.error(f"ë²¡í„° DB ë¶ˆëŸ¬ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    logger.error(f"ë²¡í„° DB ë¡œë“œ ì˜¤ë¥˜: {e}")

        # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
        chat_container = st.container()
        with chat_container:
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.write(message["content"])

        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
            st.session_state.messages.append({"role": "user", "content": query})
            
            with st.chat_message("user"):
                st.write(query)

            if not st.session_state.conversation:
                st.warning("ë¨¼ì € ë²¡í„° DBë¥¼ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”.")
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "ì£„ì†¡í•©ë‹ˆë‹¤. ë¨¼ì € ë²¡í„° DBë¥¼ ë¶ˆëŸ¬ì™€ì£¼ì„¸ìš”."
                })
                st.experimental_rerun()

            with st.chat_message("assistant"):
                with st.spinner("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
                    try:
                        result = st.session_state.conversation({"question": query})
                        response = result['answer']
                        source_documents = result.get('source_documents', [])

                        st.write(response)

                        if source_documents:
                            with st.expander("ì°¸ê³  ë¬¸ì„œ"):
                                for i, doc in enumerate(source_documents[:3], 1):
                                    st.markdown(f"**ì°¸ê³  {i}:** {doc.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ëŠ” ì¶œì²˜')}")
                                    st.markdown(f"```\n{doc.page_content[:200]}...\n```")

                        st.session_state.messages.append({"role": "assistant", "content": response})

                    except Exception as e:
                        error_message = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        st.error(error_message)
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": error_message
                        })
                        logger.error(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")

    except Exception as e:
        logger.error(f"ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error("ì•± ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œê³ ì¹¨ì„ ì‹œë„í•´ì£¼ì„¸ìš”.")

if __name__ == '__main__':
    main()
